# Training configuration
learning_rate: 5e-5
gamma: 0.99  # Discount factor
lambda_gae: 0.95  # GAE lambda
clip_epsilon: 0.2  # PPO clipping parameter
value_loss_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
target_kl: 0.015
use_action_mask: true  # Whether to use action masking

# Resume training configuration
resume_from_checkpoint: null  # Path to checkpoint to resume from (null = start fresh)
resume_extend_steps: true  # If true, extend training by total_timesteps; if false, train until total_timesteps

# Training loop parameters
total_timesteps: 100000000
rollout_batch_size: 512  # Parallel environments
rollout_batches: 10  # Number of rollout batches per iteration
update_epochs: 4  # Epochs per policy update
train_batch_size: 64
save_freq: 1000000

# Buffer configuration
buffer_size: 100000
