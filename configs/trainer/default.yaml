# Training configuration
gamma: 0.99  # Discount factor
lambda_gae: 0.95  # GAE lambda
clip_epsilon: 0.2  # PPO clipping parameter
value_loss_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
target_kl: 0.05
use_action_mask: true  # Whether to use action masking
mixed_precision: bfloat16  # Mixed precision training: null (disabled), float16, or bfloat16

# Dataset limiting configuration
max_samples_per_epoch: 150000  # Maximum number of samples to use per epoch (null = use all)
shuffle_on_reset: true  # Whether to shuffle subset selection between epochs

# Optimizer configuration
optim:
  opt_name: adamw
  max_lr: 4e-4
  betas:
    - 0.9
    - 0.999
  eps: 1e-6
  weight_decay: 0.01
  warmup_steps_ratio: 0.025
  scheduler_names: 
    - constant
    - constant
  blacklist_weight_modules:
    - norm
    - embedding

# Resume training configuration
resume_from_checkpoint: null  # Path to checkpoint to resume from (null = start fresh)
resume_extend_steps: true  # If true, extend training by total_timesteps; if false, train until total_timesteps

# Training loop parameters
total_timesteps: 5000000000
rollout_batch_size: 512  # Parallel environments
rollout_batches: 8  # Number of rollout batches per iteration
update_epochs: 5  # Epochs per policy update
train_batch_size: 2048
save_freq: 100000000
max_steps: 500000
